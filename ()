# IPython log file

import pandas as pd
from pandas import DataFrame
from pandas import Series
import numpy as np
data.replace([-999, -1000], np.nan)
data = Series([1., -999., 2., -999., -1000., 3.])
data.replace([-999, -1000], np.nan)
data.replace([-999, -1000], [np.nan, 0])
data.replace({-999: 0, -1000: np.nan})
data = DataFrame(np.arange(12).reshape((3, 4)), index = ['Ohio', 'Colorado', 'New York'],
                columns = ['one', 'two', 'three', 'four'])
data.index.map(str.upper)
data.index = data.index.map(str.upper)
data
data.rename(index=str.title, columns=str.upper)
_ = data.rename(index={'OHIO': 'INDIANA'}, inplace=True)
data
data.rename(index={'OHIO': 'INDIANA'}, inplace=True)
data
ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]
bins = [18, 25, 35, 60, 100]
cats = pd.cut(ages, bins)
cats
cats.labels
cats.levels
pd.value_counts(cats)
pd.cut(ages, [18, 26, 36, 61, 100], right=False)
group_names = ['Youth', 'YoungAdult', 'MiddleAged', 'Senior']
pd.cut(ages, bins, labels=group_names)
data = np.random.randn(2)
data
data = np.random.randn(20)
data
pd.cut(data, 4, precision=2)
data = np.random.randn(1000)
data = np.random.randn(1000) # normally distributed
cats = pd.qcut(data, 4) # cut into quartiles
cats
pd.value_counts(cats)
pd.qcut(data, [0, 0.1, 0.5, 0.9, 1.])
stats =pd.qcut(data, [0, 0.1, 0.5, 0.9, 1.])
pd.value_counts(stats)
np.random.seed(12345)
data = DataFrame(np.random.randn(1000, 4))
data
data.describe
data.describe()
col = data[3]
col
col[np.abs(col) > 3]
data[(np.abs(data) > 3).any(1)]
data[np.abs(data) > 3] = np.sign(data)*3
data.describe()
df = DataFrame(np.arange(5*4).reshape(5,4))
df = DataFrame(np.arange(5*4).reshape(5,4))
df = DataFrame(np.arange(5*4).reshape(5,4))
sampler = np.random.permutation(5)
sampler
df
df
df.take(sampler)
bag = np.array([5, 7, -1, 6, 4])
sampler = np.random.randint(0, len(bag), size=10)
sampler
draws = bag.take(sampler)
draws
df = DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'b'], 'data1': range(6)})
df
pd.get_dummies(df['key'])
dummies = pd.get_dummies(df['key'], prefix='key')
dummies
df_with_dummy = df[['data1']]
df_with_dummy
df_with_dummy = df[['data1']].join(dummies)
df_with_dummy
pd.concat(df['data1'], dummies)
pd.concat(df['data1'], dummies, axis=1)
pd.concat([df['data1'], dummies], axis=1)
movies = ['movie_id', 'title', 'genres']
mnames = ['movie_id', 'title', 'genres']
mnames = ['movie_id', 'title', 'genres']
movies = pd.read_table('pydata-book-master/ch07/movies.dat', sep='::', header=None, names=mnames)
movies = pd.read_table('pydata-book-master/ch01/movies.dat', sep='::', header=None, names=mnames)
movies = pd.read_table('pydata-book-master/ch02/movies.dat', sep='::', header=None, names=mnames)
movies = pd.read_table('pydata-book-master/movielens/ch02/movies.dat', sep='::', header=None, names=mnames)
movies = pd.read_table('pydata-book-master/ch02/movielens/movies.dat', sep='::', header=None, names=mnames)
movies
movies[:10]
genre_iter = (set(x.split('|')) for x in movies.genres)
genres = sorted(set.union(*genre_iter))
genre_iter
genres = sorted(set.union(*genre_iter))
genres = sorted(set.union(*genre_iter))
genre_iter = (set(x.split('|')) for x in movies.genres)
genres = sorted(set.union(*genre_iter))
dummies = DataFrame(np.zeros((len(movies), len(genres))), columns=genres)
genres
dummies = DataFrame(np.zeros((len(movies), len(genres))), columns=genres)
dummies
dummies
for i, gen in enumerate(movies.genres):
    dummies.ix[i, gen.split('|')] = 1
movies_windic = movies.join(dummies.add_prefix('Genre_'))
movies_windic_ix[0]
movies_windic.ix[0]
values = np.random.randn(10)
values
pd.get_dummies(pd.cut(values, bins))
pd.cut(values, bins)
values
bins = [0, 0.2, 0.4, 0.6, 0.8, 1]
pd.get_dummies(pd.cut(values, bins))
pd.cut(values, bins)
import re
text = "foo     bar\t baz \tqux"
text
re.split('\s+', text)
regex = re.compile('\s+')
regex.split(text)
regex.findall(text)
re.findall('\s+', text)
text = """Dave dave@google.com
Steve steve@gmail.com
Rob rob@gmail.com
Ryan ryan@yahoo.com
"""
pattern = r'[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,4}'
regex = re.compile(pattern, flags=re.IGNORECASE)
regex.findall(text)
m = regex.search(text)
m
print(regex.match(text))
print(regex.sub('REDACTED', text))
pattern = r'([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\.([A-Z]{2,4})'
regex = re.compile(pattern, flags=re.IGNORECASE)
m = regex.match('wesm@bright.net')
m.groups()
m = regex.match('wesm@bright.net')
m.groups()
regex.findall(text)
regex.findall(text)
print(regex.sub(r'Username: \1, Domain: \2, Suffix: \3', text))
m = regex.match('wesm@bright.net')
m.groupdict()
regex = re.compile(r"""
(?P<username>[A-Z0-9._%+-]+)
@
(?P<domain>[A-Z0-9.-]+)
\.
(?P<suffix>[A-Z]{2,4})""", flags=re.IGNORECASE|re.VERBOSE)
m = regex.match('wesm@bright.net')
m.groupdict()
data = {'Dave': 'dave@google.com', 'Steve': 'steve@gmail.com', 'Rob': 'rob@gmail.com', 
       'Wes': np.nan}
data = Series(data)
data.str.contains('gmail')
pattern
get_ipython().magic('logstart ()')
